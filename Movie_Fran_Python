import pandas as pd
Movie_Revenue = pd.read_csv("https://drive.google.com/uc?export=download&id=1uo6ixKfZHxwu1egSpq8jB9RFlDHGGOWT")
Ref_Franchise = pd.read_csv("https://drive.google.com/uc?export=download&id=1UTNbUkAKdSw6OPT2AGstS0yw1xKxLFKq")
Ref_Genre = pd.read_csv("https://drive.google.com/uc?export=download&id=1kTAF4MKMvMIATgrQb5xgyl_W_mMUBI6t")
Ref_Director = pd.read_csv("https://drive.google.com/uc?export=download&id=1bBUq0DYkzQ3A5rzfZGjHCw-4TFcCctoB")
Ref_Cast = pd.read_csv("https://drive.google.com/uc?export=download&id=1ZVyCGz7uZOWYuqKX2oNzO2LIrTook6bL")

Movie_Revenue['ReleaseDate'] = pd.to_datetime(Movie_Revenue['ReleaseDate'], format='%m/%d/%Y')
Movie_Revenue = Movie_Revenue.rename(columns={'Lifetime Gross': 'Lifetime_Gross'})

import sqlite3 as db
conn = db.connect("Movie.db")
Movie_Revenue.to_sql('Movie_Revenue', conn, if_exists='replace', index=False)
Ref_Franchise.to_sql('Ref_Franchise', conn, if_exists='replace', index=False)
Ref_Genre.to_sql('Ref_Genre', conn, if_exists='replace', index=False)
Ref_Director.to_sql('Ref_Director', conn, if_exists='replace', index=False)
Ref_Cast.to_sql('Ref_Cast', conn, if_exists='replace', index=False)


query = '''
SELECT Movie_Revenue.MovieID,
Ref_Franchise.FranchiseId,
Movie_Revenue.Title,
Movie_Revenue.Lifetime_Gross,
Movie_Revenue.Year,
Movie_Revenue.Rating,
Movie_Revenue.Runtime,
Movie_Revenue.Budget,
Ref_Franchise.FranchiseName
FROM Movie_Revenue
LEFT JOIN Ref_Franchise ON (Movie_Revenue.FranchiseID=Ref_Franchise.FranchiseId)
'''
Fran_data = pd.read_sql_query(query, conn)

conn.close()

import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn import linear_model as lm
from sklearn import model_selection as ms

X_test = Fran_data.groupby('FranchiseName').sample(n=1, random_state=123)
print(len(X_test))
X_train = Fran_data[~Fran_data.index.isin(X_test.index)]
print(len(X_train))
y = Fran_data['Lifetime_Gross'].to_numpy()
y_test = y[X_test.index]
print(len(y_test))
mask = np.ones(y.shape, dtype=bool)
mask[X_test.index] = False
y_train = y[mask]
print(len(y_train))

def standardize(arr):
  """Standardizes a NumPy array."""
  mean = np.mean(arr)
  std = np.std(arr)
  return (arr - mean) / std

y_train = standardize(y_train)
y_test = standardize(y_test)

X_dummies = pd.get_dummies(X_train[['Rating', 'FranchiseName']])
X_dummies.reset_index(drop=True,inplace=True)
scaler = StandardScaler()
X_train_sub = X_train[['Year', 'Runtime', 'Budget']]
X_train = scaler.fit_transform(X_train_sub)
X_train = pd.DataFrame(X_train, columns=X_train_sub.columns)
X_train = pd.concat([X_train,X_dummies], axis=1)
X_train[X_train.isna().any(axis=1)]

X_dummies = pd.get_dummies(X_test[['Rating', 'FranchiseName']])
X_dummies.reset_index(drop=True,inplace=True)
scaler = StandardScaler()
X_test_sub = X_test[['Year', 'Runtime', 'Budget']]
X_test = scaler.fit_transform(X_test_sub)
X_test = pd.DataFrame(X_test, columns=X_test_sub.columns)
X_test = pd.concat([X_test,X_dummies], axis=1)
X_test[X_test.isna().any(axis=1)]

k = len(X_train)-1
lasso_cv = lm.LassoCV(cv=k)
fit = lasso_cv.fit(X_train, y_train)

fit.alpha_

coef = pd.DataFrame(fit.coef_)
coef = coef.T
coef.columns = X_train.columns
coef
# it looks as thought the LassoCV chose a model with Year Runtime and Budget as predictors along with two components of the FranchiseName included
# to remove the other franchises from the dataset would significantly truncate the dataset so we will move forward with using the whole FranchiseName column

y_test_resid = y_test - np.mean(y_test)
TSS = sum((y_test_resid)**2)
RSS = sum((y_test-y_hat)**2)
R_sq = 1 - (RSS/TSS)
1-((1-R_sq)*(len(X_test)-1)/(len(X_test)-5-1)
# the adjusted coefficient of determination needs more than 5 values

